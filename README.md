# ‚úÖ mon-projet-etl

**Projet ETL (Scala)** pour parser, valider et analyser des jeux de donn√©es sur les pays du monde.

---

## üöÄ Pr√©sentation

Ce projet ex√©cute un pipeline ETL simple : il charge des fichiers JSON de pays, filtre les donn√©es invalides, supprime les doublons, calcule des statistiques (top 10 par population, superficie, r√©partition par continent, langues les plus courantes, etc.) et produit un rapport JSON.


## üîß Fonctionnalit√©s principales

- Chargement des datasets : `countries/data_clean.json`, `countries/data_dirty.json`, `countries/data_large.json`
- Validation des enregistrements (population > 0, champs non vides, etc.)
- Suppression des doublons (par `code`)
- Calculs statistiques : top 10 population / area / gdp, counts et moyennes par continent, langues les plus communes
- √âcriture d'un fichier de sortie JSON : `results_<dataset>.json`


## üìÅ Structure du projet

- `countries/` : jeux de donn√©es source
- `src/main/scala/projetEtl/` : code source
  - `Main.scala` : orchestration du pipeline (ex√©cute les 3 datasets)
  - `DataLoader.scala` : lecture/parsing JSON
  - `DataValidator.scala` : r√®gles de validation et suppression de doublons
  - `StatsCalculator.scala` : calculs et agr√©gations
  - `ReportGenerator.scala` : g√©n√©ration et √©criture du rapport JSON
  - `Countries.scala` : mod√®les de donn√©es (case classes)
- `build.sbt` : configuration SBT (Scala 3.3.7, d√©pendances Circe)




## Installation & ex√©cution

1. Ouvrir un terminal √† la racine du projet :

```bash
cd mon-projet-etl
```

2. Compiler :

```bash
sbt compile
```

3. Lancer le pipeline (ex√©cute les 3 datasets list√©s dans `Main`):

```bash
sbt run
```

Fichiers de sortie g√©n√©r√©s : `results_data_clean.json`, `results_data_dirty.json`, `results_data_large.json` (cr√©√©s √† la racine du projet).


## Tests

Le projet utilise `munit` pour les tests (d√©pendance d√©clar√©e). Ex√©cutez :

```bash
sbt test
```
